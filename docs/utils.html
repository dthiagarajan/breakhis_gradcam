---

title: Utilities

keywords: fastai
sidebar: home_sidebar

summary: "The utility functions here can be used for training and evaluation of the model."
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: 02_utils.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
    
<div class="cell border-box-sizing code_cell rendered">

</div>
<div class="cell border-box-sizing code_cell rendered">

</div>
<div class="cell border-box-sizing code_cell rendered">

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="mixup_data" class="doc_header"><code>mixup_data</code><a href="https://github.com/dthiagarajan/breakhis_gradcam/tree/master/breakhis_gradcam/utils.py#L16" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>mixup_data</code>(<strong><code>x</code></strong>, <strong><code>y</code></strong>, <strong><code>criterion</code></strong>, <strong><code>alpha</code></strong>=<em><code>1.0</code></em>)</p>
</blockquote>
<p>Compute the mixup data for batch <code>x, y</code>. Return mixed inputs, pairs of targets, and lambda.</p>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This function is called in train if <code>mixup</code> is specified as true.</p>
<ul>
<li><code>x</code>, <code>y</code> should be <code>torch.Tensor</code></li>
<li><code>criterion</code> should be a <code>torch</code> loss function, e.g. <code>nn.CrossEntropyLoss</code></li>
<li><code>alpha</code> is a float defining the distribution for sampling the mixing value (see the Mixup paper for details)</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="train" class="doc_header"><code>train</code><a href="https://github.com/dthiagarajan/breakhis_gradcam/tree/master/breakhis_gradcam/utils.py#L44" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>train</code>(<strong><code>model</code></strong>, <strong><code>epoch</code></strong>, <strong><code>dataloader</code></strong>, <strong><code>criterion</code></strong>, <strong><code>optimizer</code></strong>, <strong><code>scheduler</code></strong>=<em><code>None</code></em>, <strong><code>mixup</code></strong>=<em><code>False</code></em>, <strong><code>alpha</code></strong>=<em><code>0.4</code></em>, <strong><code>logging_frequency</code></strong>=<em><code>50</code></em>)</p>
</blockquote>
<p>Trains <code>model</code> on data in <code>dataloader</code> with loss <code>criterion</code> and optimization scheme
defined by <code>optimizer</code>, with optional learning schedule defined by <code>scheduler</code>. This
function calls performs 1 epoch - passing in <code>epoch</code> is purely for logging clarity.
Logs every <code>logging_frequency</code> iterations.</p>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This function performs 1 epoch of training.</p>
<ul>
<li><code>model</code> should be a <code>torch.nn.Module</code></li>
<li><code>epoch</code> should indicate the current epoch of training, and is only really necessary for logging purposes.</li>
<li><code>dataloader should be a</code>torch.utils.data.DataLoader<code>wrapping a</code>BreaKHisDataset` object</li>
<li><code>criterion</code> should be a <code>torch</code> loss function</li>
<li><code>optimizer</code> should be a <code>torch.optim.Optimizer</code>, e.g. Adam</li>
<li><code>scheduler</code> is optional, but when included, should be a <code>torch.optim._LRScheduler</code>, e.g. CyclicLR</li>
<li><code>mixup</code> is a boolean indicating whether to use mixup augmentation for training (default is False)</li>
<li><code>alpha</code> is a float determining the distribution for sampling the mixing ratio</li>
<li><code>logging_frequency</code> determines the cycle of iterations before logging metrics</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="validate" class="doc_header"><code>validate</code><a href="https://github.com/dthiagarajan/breakhis_gradcam/tree/master/breakhis_gradcam/utils.py#L98" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>validate</code>(<strong><code>model</code></strong>, <strong><code>epoch</code></strong>, <strong><code>dataloader</code></strong>, <strong><code>criterion</code></strong>, <strong><code>tta</code></strong>=<em><code>False</code></em>, <strong><code>tta_mixing</code></strong>=<em><code>0.6</code></em>, <strong><code>logging_frequency</code></strong>=<em><code>50</code></em>)</p>
</blockquote>
<p>Validates <code>model</code> on data in <code>dataloader</code> for epoch <code>epoch</code> using objective <code>criterion</code>.</p>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This function performs 1 epoch of validation.</p>
<ul>
<li><code>model</code> should be a <code>torch.nn.Module</code></li>
<li><code>epoch</code> should indicate the current epoch of training, and is only really necessary for logging purposes.</li>
<li><code>dataloader should be a</code>torch.utils.data.DataLoader<code>wrapping a</code>BreaKHisDataset` object</li>
<li><code>criterion</code> should be a <code>torch</code> loss function</li>
<li><code>optimizer</code> should be a <code>torch.optim.Optimizer</code>, e.g. Adam</li>
<li><code>tta</code> is a boolean indicating whether to use test-time augmentation (default is False)</li>
<li><code>tta_mixing</code> determines how much of the test-time augmented data to use in determining the final output (default is 0.6)</li>
<li><code>logging_frequency</code> determines the cycle of iterations before logging metrics</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Here are some toy examples using the functions defined above. For brevity, we use a small subset of the dataset.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">breakhis_gradcam.data</span> <span class="kn">import</span> <span class="n">initialize_datasets</span>
<span class="kn">from</span> <span class="nn">breakhis_gradcam.resnet</span> <span class="kn">import</span> <span class="n">resnet18</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">transforms</span>

<span class="k">def</span> <span class="nf">get_tta_transforms</span><span class="p">(</span><span class="n">resize_shape</span><span class="p">,</span> <span class="n">normalize_transform</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">5</span><span class="p">):</span>
    <span class="n">tta</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">RandomRotation</span><span class="p">(</span><span class="mi">15</span><span class="p">),</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">RandomResizedCrop</span><span class="p">((</span><span class="n">resize_shape</span><span class="p">,</span> <span class="n">resize_shape</span><span class="p">)),</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">RandomHorizontalFlip</span><span class="p">(),</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">ColorJitter</span><span class="p">(</span><span class="n">brightness</span><span class="o">=</span><span class="mf">0.4</span><span class="p">,</span> <span class="n">contrast</span><span class="o">=</span><span class="mf">0.4</span><span class="p">,</span> <span class="n">saturation</span><span class="o">=</span><span class="mf">0.4</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="mf">0.1</span><span class="p">),</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">()</span>
    <span class="p">])</span>
    <span class="n">original_transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">Resize</span><span class="p">((</span><span class="n">resize_shape</span><span class="p">,</span> <span class="n">resize_shape</span><span class="p">)),</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">()</span>
    <span class="p">])</span>
    <span class="k">return</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">Lambda</span><span class="p">(</span>
            <span class="k">lambda</span> <span class="n">image</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span>
                <span class="p">[</span><span class="n">tta</span><span class="p">(</span><span class="n">image</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">)]</span> <span class="o">+</span> <span class="p">[</span><span class="n">original_transform</span><span class="p">(</span><span class="n">image</span><span class="p">)]</span>
            <span class="p">)</span>
        <span class="p">),</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">Lambda</span><span class="p">(</span>
            <span class="k">lambda</span> <span class="n">images</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span>
                <span class="n">normalize_transform</span><span class="p">(</span><span class="n">image</span><span class="p">)</span> <span class="k">for</span> <span class="n">image</span> <span class="ow">in</span> <span class="n">images</span>
            <span class="p">])</span>
        <span class="p">),</span>
    <span class="p">])</span>

<span class="k">def</span> <span class="nf">get_transforms</span><span class="p">(</span><span class="n">resize_shape</span><span class="p">,</span> <span class="n">tta</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">tta_n</span><span class="o">=</span><span class="mi">5</span><span class="p">):</span>
    <span class="n">random_resized_crop</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">RandomResizedCrop</span><span class="p">((</span><span class="n">resize_shape</span><span class="p">,</span> <span class="n">resize_shape</span><span class="p">))</span>
    <span class="n">random_horizontal_flip</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">RandomHorizontalFlip</span><span class="p">()</span>
    <span class="n">resize</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Resize</span><span class="p">((</span><span class="n">resize_shape</span><span class="p">,</span> <span class="n">resize_shape</span><span class="p">))</span>
    <span class="n">normalize</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">(</span>
        <span class="n">mean</span><span class="o">=</span><span class="p">[</span><span class="mf">0.485</span><span class="p">,</span> <span class="mf">0.456</span><span class="p">,</span> <span class="mf">0.406</span><span class="p">],</span> <span class="n">std</span><span class="o">=</span><span class="p">[</span><span class="mf">0.229</span><span class="p">,</span> <span class="mf">0.224</span><span class="p">,</span> <span class="mf">0.225</span><span class="p">]</span>
    <span class="p">)</span>
    <span class="n">train_transforms</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
        <span class="n">random_resized_crop</span><span class="p">,</span> <span class="n">random_horizontal_flip</span><span class="p">,</span> <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span> <span class="n">normalize</span>
    <span class="p">])</span>
    <span class="n">val_transforms</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">get_tta_transforms</span><span class="p">(</span><span class="n">resize_shape</span><span class="p">,</span> <span class="n">normalize</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="n">tta_n</span><span class="p">)</span> <span class="k">if</span> <span class="n">tta</span>
        <span class="k">else</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span><span class="n">resize</span><span class="p">,</span> <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span> <span class="n">normalize</span><span class="p">])</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">train_transforms</span><span class="p">,</span> <span class="n">val_transforms</span>
    
<span class="n">train_transform</span><span class="p">,</span> <span class="n">val_transform</span> <span class="o">=</span> <span class="n">get_transforms</span><span class="p">(</span><span class="mi">224</span><span class="p">,</span> <span class="n">tta</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">ds_mapping</span> <span class="o">=</span> <span class="n">initialize_datasets</span><span class="p">(</span>
    <span class="s1">&#39;/share/nikola/export/dt372/BreaKHis_v1/&#39;</span><span class="p">,</span>
    <span class="n">label</span><span class="o">=</span><span class="s1">&#39;tumor_class&#39;</span><span class="p">,</span> <span class="n">criterion</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;tumor_type&#39;</span><span class="p">,</span> <span class="s1">&#39;magnification&#39;</span><span class="p">],</span>
    <span class="n">split_transforms</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;train&#39;</span><span class="p">:</span> <span class="n">train_transform</span><span class="p">,</span> <span class="s1">&#39;val&#39;</span><span class="p">:</span> <span class="n">val_transform</span><span class="p">}</span>
<span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tr_ds</span><span class="p">,</span> <span class="n">val_ds</span> <span class="o">=</span> <span class="n">ds_mapping</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">],</span> <span class="n">ds_mapping</span><span class="p">[</span><span class="s1">&#39;val&#39;</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tr_dl</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">tr_ds</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">val_dl</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">val_ds</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tr_loss</span><span class="p">,</span> <span class="n">tr_acc</span> <span class="o">=</span> <span class="n">train</span><span class="p">(</span>
    <span class="n">model</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">tr_dl</span><span class="p">,</span> <span class="n">criterion</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">],</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">mixup</span><span class="o">=</span><span class="n">mixup</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.4</span><span class="p">,</span>
    <span class="n">logging_frequency</span><span class="o">=</span><span class="mi">25</span>
<span class="p">)</span>
<span class="n">val_loss</span><span class="p">,</span> <span class="n">val_acc</span> <span class="o">=</span> <span class="n">validate</span><span class="p">(</span>
    <span class="n">model</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">val_dl</span><span class="p">,</span> <span class="n">criterion</span><span class="p">[</span><span class="s1">&#39;val&#39;</span><span class="p">],</span> <span class="n">tta</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">logging_frequency</span><span class="o">=</span><span class="mi">25</span>
<span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>[Epoch 0, Iteration 25 / 198] Training Loss: 0.46333, Training Accuracy: 2.17543 [Projected Accuracy: 17.22939]
[Epoch 0, Iteration 50 / 198] Training Loss: 0.47674, Training Accuracy: 4.24937 [Projected Accuracy: 16.82749]
[Epoch 0, Iteration 75 / 198] Training Loss: 0.48411, Training Accuracy: 6.35830 [Projected Accuracy: 16.78590]
[Epoch 0, Iteration 100 / 198] Training Loss: 0.47731, Training Accuracy: 8.50142 [Projected Accuracy: 16.83282]
[Epoch 0, Iteration 125 / 198] Training Loss: 0.47459, Training Accuracy: 10.64962 [Projected Accuracy: 16.86900]
[Epoch 0, Iteration 150 / 198] Training Loss: 0.47411, Training Accuracy: 12.74208 [Projected Accuracy: 16.81955]
[Epoch 0, Iteration 175 / 198] Training Loss: 0.47475, Training Accuracy: 14.79908 [Projected Accuracy: 16.74410]
[Epoch 0, Iteration 25 / 50] Validation Loss: 0.42023, Validation Accuracy: 0.44005 [Validation Accuracy: 0.88010]
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="get_param_lr_maps" class="doc_header"><code>get_param_lr_maps</code><a href="https://github.com/dthiagarajan/breakhis_gradcam/tree/master/breakhis_gradcam/utils.py#L146" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>get_param_lr_maps</code>(<strong><code>model</code></strong>, <strong><code>base_lr</code></strong>, <strong><code>finetune_body_factor</code></strong>)</p>
</blockquote>
<p>Output parameter LR mappings for setting up an optimizer for <code>model</code>.</p>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This function is useful for setting up parameter to LR mappings for fine-tuning the model. Specifically:</p>
<ul>
<li><code>model</code> should be a <code>torch.nn.Module</code></li>
<li><code>base_lr</code> should be a float, defining the LR for the linear head</li>
<li><code>finetune_body_factor</code> should be a list of two floats: a lower bound factor and upper bound factor. The learning rate for the body of the model will be equally (log) spaced between (<code>base_lr</code> <em> <code>lower_bound_factor</code>) and (<code>base_lr</code> </em> <code>upper_bound_factor</code>)</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="setup_optimizer_and_scheduler" class="doc_header"><code>setup_optimizer_and_scheduler</code><a href="https://github.com/dthiagarajan/breakhis_gradcam/tree/master/breakhis_gradcam/utils.py#L179" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>setup_optimizer_and_scheduler</code>(<strong><code>param_lr_maps</code></strong>, <strong><code>base_lr</code></strong>, <strong><code>epochs</code></strong>, <strong><code>steps_per_epoch</code></strong>)</p>
</blockquote>
<p>Create a PyTorch AdamW optimizer and OneCycleLR scheduler with <code>param_lr_maps</code> parameter mapping,
with base LR <code>base_lr</code>, for training for <code>epochs</code> epochs, with <code>steps_per_epoch</code> iterations
per epoch.</p>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="checkpoint_state" class="doc_header"><code>checkpoint_state</code><a href="https://github.com/dthiagarajan/breakhis_gradcam/tree/master/breakhis_gradcam/utils.py#L189" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>checkpoint_state</code>(<strong><code>model</code></strong>, <strong><code>epoch</code></strong>, <strong><code>optimizer</code></strong>, <strong><code>scheduler</code></strong>, <strong><code>train_loss</code></strong>, <strong><code>train_acc</code></strong>, <strong><code>val_loss</code></strong>, <strong><code>val_acc</code></strong>, <strong><code>model_dir</code></strong>=<em><code>'/share/nikola/export/dt372/breakhis_gradcam/models'</code></em>)</p>
</blockquote>
<p>Checkpoint the state of the system, including <code>model</code> state, <code>optimizer</code> state, <code>scheduler</code>
state, for <code>epoch</code>, saving the metrics as well.</p>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In the below example, you can see how to set up the optimizer and scheduler to fine-tune using the one-cycle LR scheme. The linear head is fine-tuned with a learning rate of $10^{-3}$, and the body is fine-tuned with a learning rate spaced between $10^{-8}$ and $10^{-5}$.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">resnet18</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
<span class="n">mixup</span> <span class="o">=</span> <span class="kc">True</span>
<span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">base_lr</span> <span class="o">=</span> <span class="mf">1e-3</span>
<span class="n">finetune_body_factor</span> <span class="o">=</span> <span class="p">[</span><span class="mf">1e-5</span><span class="p">,</span> <span class="mf">1e-2</span><span class="p">]</span>
<span class="n">param_lr_maps</span> <span class="o">=</span> <span class="n">get_param_lr_maps</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">base_lr</span><span class="p">,</span> <span class="n">finetune_body_factor</span><span class="p">)</span>
<span class="n">optimizer</span><span class="p">,</span> <span class="n">scheduler</span> <span class="o">=</span> <span class="n">setup_optimizer_and_scheduler</span><span class="p">(</span><span class="n">param_lr_maps</span><span class="p">,</span> <span class="n">base_lr</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">tr_dl</span><span class="p">))</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;train&#39;</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">(</span><span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;none&#39;</span> <span class="k">if</span> <span class="n">mixup</span> <span class="k">else</span> <span class="s1">&#39;mean&#39;</span><span class="p">),</span>
    <span class="s1">&#39;val&#39;</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
<span class="p">}</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>Setting up optimizer to fine-tune body with LR in range [0.00000001, 0.00001000] and head with LR 0.00100
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>A simple training loop would look like the following. Note that:</p>
<ul>
<li>The one-cycle LR scheduler is passed in, and the logic for updating that is handled in <a href="/breakhis_gradcam/utils#train"><code>train</code></a></li>
<li>Different criterion are used for training and validation. This is because the criterion for mixup is different for each batch, due to the mixing factor, so the criterion is modified in the loop for training, so the reduction is handled there, whereas reduction is standard when evaluating in validation (i.e. mean reduction)</li>
<li>Test-time augmentation is done in validation. Note that this will require having a special augmentation scheme, so validation transforms will need to be set appropriately. You can see above for an example of how to do that.</li>
<li>The model state is checkpointed each epoch. After checkpointing the state of the model and system, the directory where the state was saved can be accessed by inspecting <code>model.save_dir</code>.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
    <span class="n">tr_loss</span><span class="p">,</span> <span class="n">tr_acc</span> <span class="o">=</span> <span class="n">train</span><span class="p">(</span>
        <span class="n">model</span><span class="p">,</span> <span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">tr_dl</span><span class="p">,</span> <span class="n">criterion</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">],</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">scheduler</span><span class="o">=</span><span class="n">scheduler</span><span class="p">,</span>
        <span class="n">mixup</span><span class="o">=</span><span class="n">mixup</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.4</span><span class="p">,</span> <span class="n">logging_frequency</span><span class="o">=</span><span class="mi">25</span>
    <span class="p">)</span>
    <span class="n">val_loss</span><span class="p">,</span> <span class="n">val_acc</span> <span class="o">=</span> <span class="n">validate</span><span class="p">(</span>
        <span class="n">model</span><span class="p">,</span> <span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">val_dl</span><span class="p">,</span> <span class="n">criterion</span><span class="p">[</span><span class="s1">&#39;val&#39;</span><span class="p">],</span> <span class="n">tta</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">logging_frequency</span><span class="o">=</span><span class="mi">25</span>
    <span class="p">)</span>
    <span class="n">checkpoint_state</span><span class="p">(</span>
        <span class="n">model</span><span class="p">,</span> <span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">scheduler</span><span class="p">,</span> <span class="n">tr_loss</span><span class="p">,</span> <span class="n">tr_acc</span><span class="p">,</span> <span class="n">val_loss</span><span class="p">,</span> <span class="n">val_acc</span><span class="p">,</span>
    <span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>[Epoch 1, Iteration 25 / 198] Training Loss: 0.61779, Training Accuracy: 1.66688 [Projected Accuracy: 13.20167]
[Epoch 1, Iteration 50 / 198] Training Loss: 0.53964, Training Accuracy: 3.76124 [Projected Accuracy: 14.89452]
[Epoch 1, Iteration 75 / 198] Training Loss: 0.50664, Training Accuracy: 5.83344 [Projected Accuracy: 15.40028]
[Epoch 1, Iteration 100 / 198] Training Loss: 0.50104, Training Accuracy: 7.81111 [Projected Accuracy: 15.46601]
[Epoch 1, Iteration 125 / 198] Training Loss: 0.49492, Training Accuracy: 10.04433 [Projected Accuracy: 15.91022]
[Epoch 1, Iteration 150 / 198] Training Loss: 0.48815, Training Accuracy: 12.14424 [Projected Accuracy: 16.03039]
[Epoch 1, Iteration 175 / 198] Training Loss: 0.48081, Training Accuracy: 14.39566 [Projected Accuracy: 16.28766]
[Epoch 1, Iteration 25 / 50] Validation Loss: 0.50810, Validation Accuracy: 0.38920 [Validation Accuracy: 0.77841]
[Epoch 2, Iteration 25 / 198] Training Loss: 0.44745, Training Accuracy: 2.18651 [Projected Accuracy: 17.31716]
[Epoch 2, Iteration 50 / 198] Training Loss: 0.44490, Training Accuracy: 4.31444 [Projected Accuracy: 17.08518]
[Epoch 2, Iteration 75 / 198] Training Loss: 0.43113, Training Accuracy: 6.45250 [Projected Accuracy: 17.03460]
[Epoch 2, Iteration 100 / 198] Training Loss: 0.42757, Training Accuracy: 8.56523 [Projected Accuracy: 16.95916]
[Epoch 2, Iteration 125 / 198] Training Loss: 0.42541, Training Accuracy: 10.73876 [Projected Accuracy: 17.01019]
[Epoch 2, Iteration 150 / 198] Training Loss: 0.42320, Training Accuracy: 12.91450 [Projected Accuracy: 17.04714]
[Epoch 2, Iteration 175 / 198] Training Loss: 0.42172, Training Accuracy: 15.05478 [Projected Accuracy: 17.03341]
[Epoch 2, Iteration 25 / 50] Validation Loss: 0.31465, Validation Accuracy: 0.47646 [Validation Accuracy: 0.95292]
[Epoch 3, Iteration 25 / 198] Training Loss: 0.41465, Training Accuracy: 2.23876 [Projected Accuracy: 17.73097]
[Epoch 3, Iteration 50 / 198] Training Loss: 0.39440, Training Accuracy: 4.43762 [Projected Accuracy: 17.57297]
[Epoch 3, Iteration 75 / 198] Training Loss: 0.40363, Training Accuracy: 6.61241 [Projected Accuracy: 17.45677]
[Epoch 3, Iteration 100 / 198] Training Loss: 0.40729, Training Accuracy: 8.78230 [Projected Accuracy: 17.38895]
[Epoch 3, Iteration 125 / 198] Training Loss: 0.40448, Training Accuracy: 11.01662 [Projected Accuracy: 17.45033]
[Epoch 3, Iteration 150 / 198] Training Loss: 0.40535, Training Accuracy: 13.25095 [Projected Accuracy: 17.49125]
[Epoch 3, Iteration 175 / 198] Training Loss: 0.40613, Training Accuracy: 15.48638 [Projected Accuracy: 17.52174]
[Epoch 3, Iteration 25 / 50] Validation Loss: 0.55899, Validation Accuracy: 0.35782 [Validation Accuracy: 0.71563]
[Epoch 4, Iteration 25 / 198] Training Loss: 0.39973, Training Accuracy: 2.23939 [Projected Accuracy: 17.73598]
[Epoch 4, Iteration 50 / 198] Training Loss: 0.39833, Training Accuracy: 4.40279 [Projected Accuracy: 17.43503]
[Epoch 4, Iteration 75 / 198] Training Loss: 0.38543, Training Accuracy: 6.70108 [Projected Accuracy: 17.69084]
[Epoch 4, Iteration 100 / 198] Training Loss: 0.38818, Training Accuracy: 8.88474 [Projected Accuracy: 17.59178]
[Epoch 4, Iteration 125 / 198] Training Loss: 0.38387, Training Accuracy: 11.10038 [Projected Accuracy: 17.58300]
[Epoch 4, Iteration 150 / 198] Training Loss: 0.37873, Training Accuracy: 13.32695 [Projected Accuracy: 17.59157]
[Epoch 4, Iteration 175 / 198] Training Loss: 0.37771, Training Accuracy: 15.57853 [Projected Accuracy: 17.62599]
[Epoch 4, Iteration 25 / 50] Validation Loss: 0.29945, Validation Accuracy: 0.48964 [Validation Accuracy: 0.97928]
[Epoch 5, Iteration 25 / 198] Training Loss: 0.35548, Training Accuracy: 2.35893 [Projected Accuracy: 18.68272]
[Epoch 5, Iteration 50 / 198] Training Loss: 0.34854, Training Accuracy: 4.55272 [Projected Accuracy: 18.02878]
[Epoch 5, Iteration 75 / 198] Training Loss: 0.35551, Training Accuracy: 6.67052 [Projected Accuracy: 17.61017]
[Epoch 5, Iteration 100 / 198] Training Loss: 0.35722, Training Accuracy: 8.90991 [Projected Accuracy: 17.64162]
[Epoch 5, Iteration 125 / 198] Training Loss: 0.35682, Training Accuracy: 11.05351 [Projected Accuracy: 17.50877]
[Epoch 5, Iteration 150 / 198] Training Loss: 0.35697, Training Accuracy: 13.18857 [Projected Accuracy: 17.40891]
[Epoch 5, Iteration 175 / 198] Training Loss: 0.35440, Training Accuracy: 15.39756 [Projected Accuracy: 17.42124]
[Epoch 5, Iteration 25 / 50] Validation Loss: 0.31663, Validation Accuracy: 0.48023 [Validation Accuracy: 0.96045]
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">save_dir</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[&#39;epoch_1.pth&#39;, &#39;epoch_2.pth&#39;, &#39;epoch_3.pth&#39;, &#39;epoch_4.pth&#39;, &#39;epoch_5.pth&#39;]</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We can just use the validate method with some slight alterations to get the standard training accuracy (not the mixup accracy, which might not be as representative).</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">_</span><span class="p">,</span> <span class="n">tr_acc_no_mixup</span> <span class="o">=</span> <span class="n">validate</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">tr_dl</span><span class="p">,</span> <span class="n">criterion</span><span class="p">[</span><span class="s1">&#39;val&#39;</span><span class="p">],</span> <span class="n">tta</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">logging_frequency</span><span class="o">=</span><span class="mi">25</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training accuracy after </span><span class="si">%d</span><span class="s2"> epochs is </span><span class="si">%.5f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">tr_acc_no_mixup</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>[Epoch 5, Iteration 25 / 198] Validation Loss: 0.16696, Validation Accuracy: 0.12666 [Validation Accuracy: 1.00317]
[Epoch 5, Iteration 50 / 198] Validation Loss: 0.17132, Validation Accuracy: 0.24731 [Validation Accuracy: 0.97934]
[Epoch 5, Iteration 75 / 198] Validation Loss: 0.17119, Validation Accuracy: 0.36859 [Validation Accuracy: 0.97307]
[Epoch 5, Iteration 100 / 198] Validation Loss: 0.16980, Validation Accuracy: 0.49003 [Validation Accuracy: 0.97025]
[Epoch 5, Iteration 125 / 198] Validation Loss: 0.16848, Validation Accuracy: 0.61257 [Validation Accuracy: 0.97031]
[Epoch 5, Iteration 150 / 198] Validation Loss: 0.16889, Validation Accuracy: 0.73385 [Validation Accuracy: 0.96868]
[Epoch 5, Iteration 175 / 198] Validation Loss: 0.16793, Validation Accuracy: 0.85529 [Validation Accuracy: 0.96770]
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Training accuracy after 5 epochs is 0.95836
</pre>
</div>
</div>

</div>
</div>

</div>
</div>
 

