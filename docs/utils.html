---

title: Utilities

keywords: fastai
sidebar: home_sidebar

summary: "The utility functions here can be used for training and evaluation of the model."
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: 02_utils.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
    
<div class="cell border-box-sizing code_cell rendered">

</div>
<div class="cell border-box-sizing code_cell rendered">

</div>
<div class="cell border-box-sizing code_cell rendered">

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="mixup_data" class="doc_header"><code>mixup_data</code><a href="https://github.com/dthiagarajan/breakhis_gradcam/tree/master/breakhis_gradcam/utils.py#L20" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>mixup_data</code>(<strong><code>x</code></strong>, <strong><code>y</code></strong>, <strong><code>criterion</code></strong>, <strong><code>alpha</code></strong>=<em><code>1.0</code></em>)</p>
</blockquote>

<pre><code>Compute the mixup data for batch `x, y`. Return mixed inputs, pairs of targets, and lambda.</code></pre>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This function is called in train if <code>mixup</code> is specified as true.</p>
<ul>
<li><code>x</code>, <code>y</code> should be <code>torch.Tensor</code></li>
<li><code>criterion</code> should be a <code>torch</code> loss function, e.g. <code>nn.CrossEntropyLoss</code></li>
<li><code>alpha</code> is a float defining the distribution for sampling the mixing value (see the Mixup paper for details)</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="setup_logging_streams" class="doc_header"><code>setup_logging_streams</code><a href="https://github.com/dthiagarajan/breakhis_gradcam/tree/master/breakhis_gradcam/utils.py#L49" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>setup_logging_streams</code>(<strong><code>model</code></strong>, <strong><code>log_to_file</code></strong>=<em><code>True</code></em>, <strong><code>log_to_stdout</code></strong>=<em><code>False</code></em>)</p>
</blockquote>

<pre><code>Utility function for setting up logging handlers for `model`.</code></pre>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This function helps set up logging functionality for readable outputted metrics.</p>
<ul>
<li><code>model</code> should be the model constructed from the ResNet helper functions. They are initialized with logging and output directories by default, as long as you specify existing overarching model and logging directories.</li>
<li><code>log_to_file</code> specifies whether to output to a metrics log file in the model's logging directory</li>
<li><code>log_to_stdout</code> specifies whether to output metrics to STDOUT</li>
</ul>
<p>The function returns a closure that, when called, will clear any handlers set up in the logging module for outputting to log file or STDOUT, depending on what was specified. To avoid any confusion when logging between training runs in the same notebook, it's important to call this closure to not have redundant logging.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="train" class="doc_header"><code>train</code><a href="https://github.com/dthiagarajan/breakhis_gradcam/tree/master/breakhis_gradcam/utils.py#L82" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>train</code>(<strong><code>model</code></strong>, <strong><code>epoch</code></strong>, <strong><code>dataloader</code></strong>, <strong><code>criterion</code></strong>, <strong><code>optimizer</code></strong>, <strong><code>scheduler</code></strong>=<em><code>None</code></em>, <strong><code>mixup</code></strong>=<em><code>False</code></em>, <strong><code>alpha</code></strong>=<em><code>0.4</code></em>, <strong><code>logging_frequency</code></strong>=<em><code>50</code></em>)</p>
</blockquote>

<pre><code>Trains `model` on data in `dataloader` with loss `criterion` and optimization scheme
defined by `optimizer`, with optional learning schedule defined by `scheduler`.</code></pre>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This function performs 1 epoch of training.</p>
<ul>
<li><code>model</code> should be a <code>torch.nn.Module</code></li>
<li><code>epoch</code> should indicate the current epoch of training, and is only really necessary for logging purposes.</li>
<li><code>dataloader should be a</code>torch.utils.data.DataLoader<code>wrapping a</code>BreaKHisDataset` object</li>
<li><code>criterion</code> should be a <code>torch</code> loss function</li>
<li><code>optimizer</code> should be a <code>torch.optim.Optimizer</code>, e.g. Adam</li>
<li><code>scheduler</code> is optional, but when included, should be a <code>torch.optim._LRScheduler</code>, e.g. CyclicLR</li>
<li><code>mixup</code> is a boolean indicating whether to use mixup augmentation for training (default is False)</li>
<li><code>alpha</code> is a float determining the distribution for sampling the mixing ratio</li>
<li><code>logging_frequency</code> determines the cycle of iterations before logging metrics</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="validate" class="doc_header"><code>validate</code><a href="https://github.com/dthiagarajan/breakhis_gradcam/tree/master/breakhis_gradcam/utils.py#L134" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>validate</code>(<strong><code>model</code></strong>, <strong><code>epoch</code></strong>, <strong><code>dataloader</code></strong>, <strong><code>criterion</code></strong>, <strong><code>tta</code></strong>=<em><code>False</code></em>, <strong><code>tta_mixing</code></strong>=<em><code>0.6</code></em>, <strong><code>logging_frequency</code></strong>=<em><code>50</code></em>)</p>
</blockquote>

<pre><code>Validates `model` on data in `dataloader` for epoch `epoch` using objective `criterion`.</code></pre>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This function performs 1 epoch of validation.</p>
<ul>
<li><code>model</code> should be a <code>torch.nn.Module</code></li>
<li><code>epoch</code> should indicate the current epoch of training, and is only really necessary for logging purposes.</li>
<li><code>dataloader should be a</code>torch.utils.data.DataLoader<code>wrapping a</code>BreaKHisDataset` object</li>
<li><code>criterion</code> should be a <code>torch</code> loss function</li>
<li><code>optimizer</code> should be a <code>torch.optim.Optimizer</code>, e.g. Adam</li>
<li><code>tta</code> is a boolean indicating whether to use test-time augmentation (default is False)</li>
<li><code>tta_mixing</code> determines how much of the test-time augmented data to use in determining the final output (default is 0.6)</li>
<li><code>logging_frequency</code> determines the cycle of iterations before logging metrics</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Here are some toy examples using the functions defined above. For brevity, we use a small subset of the dataset.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#example</span>
<span class="kn">from</span> <span class="nn">breakhis_gradcam.data</span> <span class="kn">import</span> <span class="n">initialize_datasets</span>
<span class="kn">from</span> <span class="nn">breakhis_gradcam.resnet</span> <span class="kn">import</span> <span class="n">resnet18</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">transforms</span>

<span class="k">def</span> <span class="nf">get_tta_transforms</span><span class="p">(</span><span class="n">resize_shape</span><span class="p">,</span> <span class="n">normalize_transform</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="mi">5</span><span class="p">):</span>
    <span class="n">tta</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">RandomRotation</span><span class="p">(</span><span class="mi">15</span><span class="p">),</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">RandomResizedCrop</span><span class="p">((</span><span class="n">resize_shape</span><span class="p">,</span> <span class="n">resize_shape</span><span class="p">)),</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">RandomHorizontalFlip</span><span class="p">(),</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">ColorJitter</span><span class="p">(</span><span class="n">brightness</span><span class="o">=</span><span class="mf">0.4</span><span class="p">,</span> <span class="n">contrast</span><span class="o">=</span><span class="mf">0.4</span><span class="p">,</span> <span class="n">saturation</span><span class="o">=</span><span class="mf">0.4</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="mf">0.1</span><span class="p">),</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">()</span>
    <span class="p">])</span>
    <span class="n">original_transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">Resize</span><span class="p">((</span><span class="n">resize_shape</span><span class="p">,</span> <span class="n">resize_shape</span><span class="p">)),</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">()</span>
    <span class="p">])</span>
    <span class="k">return</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">Lambda</span><span class="p">(</span>
            <span class="k">lambda</span> <span class="n">image</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span>
                <span class="p">[</span><span class="n">tta</span><span class="p">(</span><span class="n">image</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">)]</span> <span class="o">+</span> <span class="p">[</span><span class="n">original_transform</span><span class="p">(</span><span class="n">image</span><span class="p">)]</span>
            <span class="p">)</span>
        <span class="p">),</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">Lambda</span><span class="p">(</span>
            <span class="k">lambda</span> <span class="n">images</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span>
                <span class="n">normalize_transform</span><span class="p">(</span><span class="n">image</span><span class="p">)</span> <span class="k">for</span> <span class="n">image</span> <span class="ow">in</span> <span class="n">images</span>
            <span class="p">])</span>
        <span class="p">),</span>
    <span class="p">])</span>

<span class="k">def</span> <span class="nf">get_transforms</span><span class="p">(</span><span class="n">resize_shape</span><span class="p">,</span> <span class="n">tta</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">tta_n</span><span class="o">=</span><span class="mi">5</span><span class="p">):</span>
    <span class="n">random_resized_crop</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">RandomResizedCrop</span><span class="p">((</span><span class="n">resize_shape</span><span class="p">,</span> <span class="n">resize_shape</span><span class="p">))</span>
    <span class="n">random_horizontal_flip</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">RandomHorizontalFlip</span><span class="p">()</span>
    <span class="n">resize</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Resize</span><span class="p">((</span><span class="n">resize_shape</span><span class="p">,</span> <span class="n">resize_shape</span><span class="p">))</span>
    <span class="n">normalize</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">(</span>
        <span class="n">mean</span><span class="o">=</span><span class="p">[</span><span class="mf">0.485</span><span class="p">,</span> <span class="mf">0.456</span><span class="p">,</span> <span class="mf">0.406</span><span class="p">],</span> <span class="n">std</span><span class="o">=</span><span class="p">[</span><span class="mf">0.229</span><span class="p">,</span> <span class="mf">0.224</span><span class="p">,</span> <span class="mf">0.225</span><span class="p">]</span>
    <span class="p">)</span>
    <span class="n">train_transforms</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
        <span class="n">random_resized_crop</span><span class="p">,</span> <span class="n">random_horizontal_flip</span><span class="p">,</span> <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span> <span class="n">normalize</span>
    <span class="p">])</span>
    <span class="n">val_transforms</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">get_tta_transforms</span><span class="p">(</span><span class="n">resize_shape</span><span class="p">,</span> <span class="n">normalize</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="n">tta_n</span><span class="p">)</span> <span class="k">if</span> <span class="n">tta</span>
        <span class="k">else</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span><span class="n">resize</span><span class="p">,</span> <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span> <span class="n">normalize</span><span class="p">])</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">train_transforms</span><span class="p">,</span> <span class="n">val_transforms</span>
    
<span class="n">train_transform</span><span class="p">,</span> <span class="n">val_transform</span> <span class="o">=</span> <span class="n">get_transforms</span><span class="p">(</span><span class="mi">224</span><span class="p">,</span> <span class="n">tta</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#example</span>
<span class="n">ds_mapping</span> <span class="o">=</span> <span class="n">initialize_datasets</span><span class="p">(</span>
    <span class="s1">&#39;/share/nikola/export/dt372/BreaKHis_v1/&#39;</span><span class="p">,</span>
    <span class="n">label</span><span class="o">=</span><span class="s1">&#39;tumor_class&#39;</span><span class="p">,</span> <span class="n">criterion</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;tumor_type&#39;</span><span class="p">,</span> <span class="s1">&#39;magnification&#39;</span><span class="p">],</span>
    <span class="n">split_transforms</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;train&#39;</span><span class="p">:</span> <span class="n">train_transform</span><span class="p">,</span> <span class="s1">&#39;val&#39;</span><span class="p">:</span> <span class="n">val_transform</span><span class="p">}</span>
<span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#example</span>
<span class="n">tr_ds</span><span class="p">,</span> <span class="n">val_ds</span> <span class="o">=</span> <span class="n">ds_mapping</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">],</span> <span class="n">ds_mapping</span><span class="p">[</span><span class="s1">&#39;val&#39;</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#example</span>
<span class="n">tr_dl</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">tr_ds</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">val_dl</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">val_ds</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#example</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">resnet18</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">AdamW</span><span class="p">([{</span><span class="s1">&#39;params&#39;</span><span class="p">:</span> <span class="n">model</span><span class="o">.</span><span class="n">out_fc</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="s1">&#39;lr&#39;</span><span class="p">:</span> <span class="mf">1e-3</span><span class="p">}])</span>
<span class="n">mixup</span> <span class="o">=</span> <span class="kc">True</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;train&#39;</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">(</span><span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;none&#39;</span> <span class="k">if</span> <span class="n">mixup</span> <span class="k">else</span> <span class="s1">&#39;mean&#39;</span><span class="p">),</span>
    <span class="s1">&#39;val&#39;</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
<span class="p">}</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The training loop might include something like the following. Note the calls to <code>clear_logging_handlers</code> - this should be included in your code as well to avoid logging redundancy.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#example</span>
<span class="n">clear_logging_handlers</span> <span class="o">=</span> <span class="n">setup_logging_streams</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">log_to_file</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">log_to_stdout</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">try</span><span class="p">:</span>
    <span class="n">tr_loss</span><span class="p">,</span> <span class="n">tr_acc</span> <span class="o">=</span> <span class="n">train</span><span class="p">(</span>
        <span class="n">model</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">tr_dl</span><span class="p">,</span> <span class="n">criterion</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">],</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">mixup</span><span class="o">=</span><span class="n">mixup</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.4</span><span class="p">,</span>
        <span class="n">logging_frequency</span><span class="o">=</span><span class="mi">25</span>
    <span class="p">)</span>
    <span class="n">val_loss</span><span class="p">,</span> <span class="n">val_acc</span> <span class="o">=</span> <span class="n">validate</span><span class="p">(</span>
        <span class="n">model</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">val_dl</span><span class="p">,</span> <span class="n">criterion</span><span class="p">[</span><span class="s1">&#39;val&#39;</span><span class="p">],</span> <span class="n">tta</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">logging_frequency</span><span class="o">=</span><span class="mi">25</span>
    <span class="p">)</span>
<span class="k">except</span> <span class="ne">BaseException</span><span class="p">:</span>
    <span class="n">clear_logging_handlers</span><span class="p">()</span>
<span class="k">finally</span><span class="p">:</span>
    <span class="n">clear_logging_handlers</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Logging to /share/nikola/export/dt372/breakhis_gradcam/logs/2020-02-16-23-18-10/metrics.log
Logging to STDOUT
[Metrics][02:16:2020:06:18:29][DEBUG]: [Epoch 0, Iteration 25 / 198] Training Loss: 0.63333, Training Accuracy: 1.94728 [Projected Accuracy: 15.42243]
[Metrics][02:16:2020:06:18:41][DEBUG]: [Epoch 0, Iteration 50 / 198] Training Loss: 0.58616, Training Accuracy: 3.94854 [Projected Accuracy: 15.63623]
[Metrics][02:16:2020:06:18:54][DEBUG]: [Epoch 0, Iteration 75 / 198] Training Loss: 0.56723, Training Accuracy: 5.90912 [Projected Accuracy: 15.60008]
[Metrics][02:16:2020:06:19:07][DEBUG]: [Epoch 0, Iteration 100 / 198] Training Loss: 0.55472, Training Accuracy: 7.89645 [Projected Accuracy: 15.63498]
[Metrics][02:16:2020:06:19:21][DEBUG]: [Epoch 0, Iteration 125 / 198] Training Loss: 0.54388, Training Accuracy: 9.99066 [Projected Accuracy: 15.82520]
[Metrics][02:16:2020:06:19:34][DEBUG]: [Epoch 0, Iteration 150 / 198] Training Loss: 0.53556, Training Accuracy: 12.05890 [Projected Accuracy: 15.91775]
[Metrics][02:16:2020:06:19:47][DEBUG]: [Epoch 0, Iteration 175 / 198] Training Loss: 0.52685, Training Accuracy: 14.26282 [Projected Accuracy: 16.13737]
[Metrics][02:16:2020:06:19:58][INFO]: Reporting 0.52171 training loss, 15.97910 training accuracy for epoch 0.
[Metrics][02:16:2020:06:20:50][DEBUG]: [Epoch 0, Iteration 25 / 50] Validation Loss: 0.41677, Validation Accuracy: 0.46014 [Validation Accuracy: 0.92028]
[Metrics][02:16:2020:06:21:36][INFO]: Reporting 0.41893 validation loss, 0.87947 validation accuracy for epoch 0.
Cleared all logging handlers
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Since we were just testing here, it might be annoying to have find the log and state files later to remove for saving memory. However, we can just do the following to resolve that (this will delete all the contents to clear the log and model/system state directory):</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#example</span>
<span class="n">model</span><span class="o">.</span><span class="n">clear_logging_and_output_dirs</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Removing directory /share/nikola/export/dt372/breakhis_gradcam/logs/2020-02-16-23-18-10 and all contents.
Removing directory /share/nikola/export/dt372/breakhis_gradcam/models/2020-02-16-23-18-10 and all contents.
Resetting /share/nikola/export/dt372/breakhis_gradcam/logs/2020-02-16-23-18-10 and /share/nikola/export/dt372/breakhis_gradcam/models/2020-02-16-23-18-10.
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="get_param_lr_maps" class="doc_header"><code>get_param_lr_maps</code><a href="https://github.com/dthiagarajan/breakhis_gradcam/tree/master/breakhis_gradcam/utils.py#L185" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>get_param_lr_maps</code>(<strong><code>model</code></strong>, <strong><code>base_lr</code></strong>, <strong><code>finetune_body_factor</code></strong>)</p>
</blockquote>

<pre><code>Output parameter LR mappings for setting up an optimizer for `model`.</code></pre>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This function is useful for setting up parameter to LR mappings for fine-tuning the model. Specifically:</p>
<ul>
<li><code>model</code> should be a <code>torch.nn.Module</code></li>
<li><code>base_lr</code> should be a float, defining the LR for the linear head</li>
<li><code>finetune_body_factor</code> should be a list of two floats: a lower bound factor and upper bound factor. The learning rate for the body of the model will be equally (log) spaced between (<code>base_lr</code> <em> <code>lower_bound_factor</code>) and (<code>base_lr</code> </em> <code>upper_bound_factor</code>)</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="setup_optimizer_and_scheduler" class="doc_header"><code>setup_optimizer_and_scheduler</code><a href="https://github.com/dthiagarajan/breakhis_gradcam/tree/master/breakhis_gradcam/utils.py#L219" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>setup_optimizer_and_scheduler</code>(<strong><code>param_lr_maps</code></strong>, <strong><code>base_lr</code></strong>, <strong><code>epochs</code></strong>, <strong><code>steps_per_epoch</code></strong>)</p>
</blockquote>

<pre><code>Create a PyTorch AdamW optimizer and OneCycleLR scheduler with `param_lr_maps` parameter mapping,
with base LR `base_lr`, for training for `epochs` epochs, with `steps_per_epoch` iterations
per epoch.</code></pre>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="checkpoint_state" class="doc_header"><code>checkpoint_state</code><a href="https://github.com/dthiagarajan/breakhis_gradcam/tree/master/breakhis_gradcam/utils.py#L229" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>checkpoint_state</code>(<strong><code>model</code></strong>, <strong><code>epoch</code></strong>, <strong><code>optimizer</code></strong>, <strong><code>scheduler</code></strong>, <strong><code>train_loss</code></strong>, <strong><code>train_acc</code></strong>, <strong><code>val_loss</code></strong>, <strong><code>val_acc</code></strong>)</p>
</blockquote>

<pre><code>Checkpoint the state of the system, including `model` state, `optimizer` state, `scheduler`
state, for `epoch`, saving the metrics as well.</code></pre>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In the below example, you can see how to set up the optimizer and scheduler to fine-tune using the one-cycle LR scheme. The linear head is fine-tuned with a learning rate of $10^{-3}$, and the body is fine-tuned with a learning rate spaced between $10^{-8}$ and $10^{-5}$.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#example</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">resnet18</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
<span class="n">mixup</span> <span class="o">=</span> <span class="kc">True</span>
<span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">base_lr</span> <span class="o">=</span> <span class="mf">1e-3</span>
<span class="n">finetune_body_factor</span> <span class="o">=</span> <span class="p">[</span><span class="mf">1e-5</span><span class="p">,</span> <span class="mf">1e-2</span><span class="p">]</span>
<span class="n">param_lr_maps</span> <span class="o">=</span> <span class="n">get_param_lr_maps</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">base_lr</span><span class="p">,</span> <span class="n">finetune_body_factor</span><span class="p">)</span>
<span class="n">optimizer</span><span class="p">,</span> <span class="n">scheduler</span> <span class="o">=</span> <span class="n">setup_optimizer_and_scheduler</span><span class="p">(</span><span class="n">param_lr_maps</span><span class="p">,</span> <span class="n">base_lr</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">tr_dl</span><span class="p">))</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;train&#39;</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">(</span><span class="n">reduction</span><span class="o">=</span><span class="s1">&#39;none&#39;</span> <span class="k">if</span> <span class="n">mixup</span> <span class="k">else</span> <span class="s1">&#39;mean&#39;</span><span class="p">),</span>
    <span class="s1">&#39;val&#39;</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
<span class="p">}</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>A simple training loop would look like the following. Note that:</p>
<ul>
<li>The one-cycle LR scheduler is passed in, and the logic for updating that is handled in <a href="/breakhis_gradcam/utils#train"><code>train</code></a></li>
<li>Different criterion are used for training and validation. This is because the criterion for mixup is different for each batch, due to the mixing factor, so the criterion is modified in the loop for training, so the reduction is handled there, whereas reduction is standard when evaluating in validation (i.e. mean reduction)</li>
<li>Test-time augmentation is done in validation. Note that this will require having a special augmentation scheme, so validation transforms will need to be set appropriately. You can see above for an example of how to do that.</li>
<li>The model state is checkpointed each epoch. After checkpointing the state of the model and system, the directory where the state was saved can be accessed by inspecting <code>model.save_dir</code>.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#example</span>
<span class="n">clear_logging_handlers</span> <span class="o">=</span> <span class="n">setup_logging_streams</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">log_to_file</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">log_to_stdout</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
    <span class="n">tr_loss</span><span class="p">,</span> <span class="n">tr_acc</span> <span class="o">=</span> <span class="n">train</span><span class="p">(</span>
        <span class="n">model</span><span class="p">,</span> <span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">tr_dl</span><span class="p">,</span> <span class="n">criterion</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">],</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">scheduler</span><span class="o">=</span><span class="n">scheduler</span><span class="p">,</span>
        <span class="n">mixup</span><span class="o">=</span><span class="n">mixup</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.4</span><span class="p">,</span> <span class="n">logging_frequency</span><span class="o">=</span><span class="mi">25</span>
    <span class="p">)</span>
    <span class="n">val_loss</span><span class="p">,</span> <span class="n">val_acc</span> <span class="o">=</span> <span class="n">validate</span><span class="p">(</span>
        <span class="n">model</span><span class="p">,</span> <span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">val_dl</span><span class="p">,</span> <span class="n">criterion</span><span class="p">[</span><span class="s1">&#39;val&#39;</span><span class="p">],</span> <span class="n">tta</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">logging_frequency</span><span class="o">=</span><span class="mi">25</span>
    <span class="p">)</span>
    <span class="n">checkpoint_state</span><span class="p">(</span>
        <span class="n">model</span><span class="p">,</span> <span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">scheduler</span><span class="p">,</span> <span class="n">tr_loss</span><span class="p">,</span> <span class="n">tr_acc</span><span class="p">,</span> <span class="n">val_loss</span><span class="p">,</span> <span class="n">val_acc</span><span class="p">,</span>
    <span class="p">)</span>
<span class="n">clear_logging_handlers</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Logging to /share/nikola/export/dt372/breakhis_gradcam/logs/2020-02-16-23-22-02/metrics.log
Cleared all logging handlers
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#example</span>
<span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">save_dir</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[&#39;epoch_1.pth&#39;, &#39;epoch_2.pth&#39;, &#39;epoch_3.pth&#39;, &#39;epoch_4.pth&#39;, &#39;epoch_5.pth&#39;]</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We can just use the validate method with some slight alterations to get the standard training accuracy (not the mixup accracy, which might not be as representative).</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#example</span>
<span class="n">_</span><span class="p">,</span> <span class="n">tr_acc_no_mixup</span> <span class="o">=</span> <span class="n">validate</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">tr_dl</span><span class="p">,</span> <span class="n">criterion</span><span class="p">[</span><span class="s1">&#39;val&#39;</span><span class="p">],</span> <span class="n">tta</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">logging_frequency</span><span class="o">=</span><span class="mi">25</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training accuracy after </span><span class="si">%d</span><span class="s2"> epochs is </span><span class="si">%.5f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">tr_acc_no_mixup</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Training accuracy after 5 epochs is 0.96358
</pre>
</div>
</div>

</div>
</div>

</div>
</div>
 

