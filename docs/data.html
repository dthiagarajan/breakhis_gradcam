---

title: Title

keywords: fastai
sidebar: home_sidebar

summary: "summary"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: 01_data.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
    
<div class="cell border-box-sizing code_cell rendered">

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="BreaKHis-Data-Processing">BreaKHis Data Processing<a class="anchor-link" href="#BreaKHis-Data-Processing">&#182;</a></h1><p>More information about the dataset can be found in the README obtained when downloading the dataset. The important information is in the appendix of this page. All images in this dataset are captured from an ROI determined by a professional pathologist, so all images are assumed to have <em>a</em> tumor.</p>
<blockquote><p>The BreaKHis dataset is organized by benign and malignant tumors, and then by the specific tumor types: - For benign tumors, the images are organized additionally by: adenosis, fibroadenoma, phyllodes_tumor, tubular_adenoma- For malignant tumors, the images are organized additionally by: ductal_carcinoma, lobular_carcinoma, mucinous_carcinoma, papillary_carcinoma</p>
<p>The functions provided here will help to quickly (lazily) process the data for usage in training image classification models, while maintaining the additional information that might not be necessary. For example, if training on benign/malignant labels, the information about which specific tumor is present will still be available in the dataset definition.</p>
<p>The data is anonymized, so there's no possibility of splitting at the patient level. Instead, we leave dataset splitting up to the user, but provide some utility functions to reproduce the results obtained in initial development.</p>
</blockquote>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">

</div>
<div class="cell border-box-sizing code_cell rendered">

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="BreaKHisDataset" class="doc_header"><code>class</code> <code>BreaKHisDataset</code><a href="https://github.com/dthiagarajan/breakhis_gradcam/tree/master/breakhis_gradcam/data.py#L14" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>BreaKHisDataset</code>(<strong><code>dataset</code></strong>, <strong><code>transform</code></strong>=<em><code>None</code></em>) :: <code>Dataset</code></p>
</blockquote>
<p>PyTorch dataset definition of the BreaKHis dataset.</p>
<p>Construction of the dataset object should be done using this
class's method <code>initialize</code>. Simply providing the data directory
where the data was downloaded is sufficient.</p>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="initialize_datasets" class="doc_header"><code>initialize_datasets</code><a href="https://github.com/dthiagarajan/breakhis_gradcam/tree/master/breakhis_gradcam/data.py#L226" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>initialize_datasets</code>(<strong><code>data_dir</code></strong>, <strong><code>label</code></strong>=<em><code>'tumor_class'</code></em>, <strong><code>split</code></strong>=<em><code>{'train': 0.8, 'val': 0.2}</code></em>, <strong><code>criterion</code></strong>=<em><code>['tumor_class']</code></em>, <strong><code>split_transforms</code></strong>=<em><code>{'train': None, 'val': None}</code></em>)</p>
</blockquote>
<p>Initializes a PyTorch dataset object for the data contained in <code>data_dir</code>.</p>
<h2 id="Arguments:">Arguments:<a class="anchor-link" href="#Arguments:">&#182;</a></h2>
<pre><code>* `data_dir` (str): the directory where the BreaKHis dataset was downloaded
* `label` (str): the label to use for the dataset (either 'tumor_class' or 'tumor_type')
* `split` (Dict[str, float]): a mapping of strings to floats corresponding to the percentage
    in each split of the dataset; must add up to 1.
* `criterion` (List[str]): one of 'tumor_class' (benign/malignant) or
    'tumor_type' (e.g. adenosis) and/or 'magnification'
* `split_transforms` (Dict[str, torchvision.transforms]): a mapping of split IDs to the
    corresponding transforms.
</code></pre>
<h2 id="Returns:">Returns:<a class="anchor-link" href="#Returns:">&#182;</a></h2>
<pre><code>* data_partitioned (Dict[str, List]): mapping of data corresponding to the split IDs
    given in `split`, and each split ID maps to a [`BreaKHisDataset`](/breakhis_gradcam/data#BreaKHisDataset) encompassing the
    list of data points, with the proper percentage of the dataset allocated to each split ID.</code></pre>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>To create the dataset, you only need one function calls. Within this function call:</p>
<ul>
<li>You can specify the label type when initializing the dataset by specifying <code>label</code> in <code>initialize</code></li>
<li>You can make arbitrary splits of the data (within reason) when splitting the dataset via <code>split_dataset</code></li>
<li>You can make sure to split equally within various criterion using <code>criterion</code>, which can include tumor class/tumor type, and magnification.</li>
<li>You can use different transforms for different splits using <code>split_transforms</code>.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">train_transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">RandomRotation</span><span class="p">(</span><span class="mi">90</span><span class="p">),</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">RandomHorizontalFlip</span><span class="p">(</span><span class="mf">0.8</span><span class="p">),</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">RandomResizedCrop</span><span class="p">(</span><span class="mi">224</span><span class="p">),</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">ColorJitter</span><span class="p">(</span><span class="n">brightness</span><span class="o">=</span><span class="mf">0.4</span><span class="p">,</span> <span class="n">contrast</span><span class="o">=</span><span class="mf">0.4</span><span class="p">,</span> <span class="n">saturation</span><span class="o">=</span><span class="mf">0.4</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="mf">0.1</span><span class="p">),</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">((</span><span class="mf">0.4914</span><span class="p">,</span> <span class="mf">0.4822</span><span class="p">,</span> <span class="mf">0.4465</span><span class="p">),</span>
                         <span class="p">(</span><span class="mf">0.2023</span><span class="p">,</span> <span class="mf">0.1994</span><span class="p">,</span> <span class="mf">0.2010</span><span class="p">)),</span>
<span class="p">])</span>

<span class="n">val_transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">CenterCrop</span><span class="p">(</span><span class="mi">224</span><span class="p">),</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
    <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">((</span><span class="mf">0.4914</span><span class="p">,</span> <span class="mf">0.4822</span><span class="p">,</span> <span class="mf">0.4465</span><span class="p">),</span>
                        <span class="p">(</span><span class="mf">0.2023</span><span class="p">,</span> <span class="mf">0.1994</span><span class="p">,</span> <span class="mf">0.2010</span><span class="p">)),</span>
<span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">ds_mapping</span> <span class="o">=</span> <span class="n">initialize_datasets</span><span class="p">(</span>
    <span class="s1">&#39;/share/nikola/export/dt372/BreaKHis_v1/&#39;</span><span class="p">,</span>
    <span class="n">label</span><span class="o">=</span><span class="s1">&#39;tumor_type&#39;</span><span class="p">,</span> <span class="n">criterion</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;tumor_type&#39;</span><span class="p">,</span> <span class="s1">&#39;magnification&#39;</span><span class="p">],</span>
    <span class="n">split_transforms</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;train&#39;</span><span class="p">:</span> <span class="n">train_transform</span><span class="p">,</span> <span class="s1">&#39;val&#39;</span><span class="p">:</span> <span class="n">val_transform</span><span class="p">}</span>
<span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tr_ds</span><span class="p">,</span> <span class="n">val_ds</span> <span class="o">=</span> <span class="n">ds_mapping</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">],</span> <span class="n">ds_mapping</span><span class="p">[</span><span class="s1">&#39;val&#39;</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tr_ds</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(tensor([[[-2.1577, -2.1577, -2.1577,  ...,  1.4091,  1.4091,  1.4091],
          [-2.1577, -2.1577, -2.1577,  ...,  1.4091,  1.4091,  1.4091],
          [-2.1577, -2.1577, -2.1577,  ...,  1.4091,  1.4091,  1.3898],
          ...,
          [ 1.2541,  1.2541,  1.2735,  ...,  1.4285,  1.3704,  1.3510],
          [ 1.2928,  1.3122,  1.2928,  ...,  1.2928,  1.3122,  1.2928],
          [ 1.3510,  1.3704,  1.3316,  ...,  1.3510,  1.3122,  1.2541]],
 
         [[-2.1429, -2.1429, -2.1429,  ...,  1.6921,  1.6921,  1.6528],
          [-2.1429, -2.1429, -2.1429,  ...,  1.7118,  1.6724,  1.6921],
          [-2.1429, -2.1429, -2.1429,  ...,  1.7314,  1.7314,  1.6724],
          ...,
          [ 0.4728,  0.3941,  0.3941,  ...,  0.9841,  0.9448,  0.9841],
          [ 0.4728,  0.4138,  0.3941,  ...,  0.8464,  0.9054,  0.8464],
          [ 0.4531,  0.4531,  0.3941,  ...,  0.8464,  0.8464,  0.7678]],
 
         [[-1.9482, -1.9482, -1.9482,  ...,  1.5831,  1.5831,  1.5831],
          [-1.9482, -1.9482, -1.9482,  ...,  1.5831,  1.5636,  1.6026],
          [-1.9482, -1.9482, -1.9482,  ...,  1.5246,  1.5246,  1.5636],
          ...,
          [ 1.3100,  1.2514,  1.3100,  ...,  1.6026,  1.5441,  1.5636],
          [ 1.3295,  1.3100,  1.3295,  ...,  1.4661,  1.4856,  1.4856],
          [ 1.3295,  1.3295,  1.3295,  ...,  1.5246,  1.4856,  1.3880]]]),
 tensor([0.]))</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">len</span><span class="p">(</span><span class="n">tr_ds</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">val_ds</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(6316, 1593)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>From here, it is very simple to create the dataloaders for use in training.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tr_dl</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">tr_ds</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">val_dl</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">val_ds</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">tr_dl</span><span class="p">))</span>
<span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(torch.Size([32, 3, 224, 224]), torch.Size([32, 1]))</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Appendix">Appendix<a class="anchor-link" href="#Appendix">&#182;</a></h2><h3 id="Samples">Samples<a class="anchor-link" href="#Samples">&#182;</a></h3><ul>
<li>Samples are generated from breast tissue biopsy slides, stained with hematoxylin and eosin (HE).</li>
<li>Prepared for histological study and labelled by pathologists of the P&amp;D Lab</li>
<li>Breast tumor specimens assessed by Immunohistochemistry (IHC)</li>
<li>Core Needle Biopsy (CNB) and Surgical Open Biopsy (SOB)</li>
<li>Section of ~3µm thickness</li>
</ul>
<h3 id="Image-acquisition">Image acquisition<a class="anchor-link" href="#Image-acquisition">&#182;</a></h3><ul>
<li>Olympus BX-50 system microscope with a relay lens with magnification of 3.3× coupled to a Samsung digital color camera SCC-131AN</li>
<li>Magnification 40×, 100×, 200×, and 400× (objective lens 4×, 10×, 20×, and 40× with ocular lens 10×)</li>
<li>Camera pixel size 6.5 µm</li>
<li>Raw images without normalization nor color color standardization</li>
<li>Resulting images saved in 3-channel RGB, 8-bit depth in each channel, PNG format</li>
</ul>

</div>
</div>
</div>
</div>
 

