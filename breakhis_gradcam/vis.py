# AUTOGENERATED! DO NOT EDIT! File to edit: 03_vis.ipynb (unless otherwise specified).

__all__ = ['show_image', 'get_preprocessed_image', 'show_heatmap_and_original']


# Cell
import cv2
import numpy as np
import pylab as plt
import torch
from PIL import Image
from torchvision import transforms

from .data import BreaKHisDataset, initialize_datasets
from .resnet import resnet18
from .utils import (
    checkpoint_state,
    get_param_lr_maps,
    setup_logging_streams,
    setup_optimizer_and_scheduler,
    train,
    validate
)


# Cell
def show_image(datapoint, ax=None):
    """Shows the image corresponding to `datapoint` (taken from a `BreaKHisDataset` object).
       Optionally provide an axis object `ax` from Matplotlib for multi-image plots."""
    (fp, tumor, subtumor, magnification, slide_id, sequence_id), label = datapoint
    image = Image.open(fp)
    if ax is None:
        plt.figure()
        out_image = plt.imshow(image)
        plt.axis('off')
        ax = plt.gca()
    else:
        out_image = ax.imshow(image)
        ax.axis('off')
    if ax is None:
        plt.show()


# Cell
def get_preprocessed_image(datapoint, inference_transform):
    """Returns the pre-processed image and corresponding label ID using the `inference_transform`."""
    (fp, tumor, subtumor, magnification, slide_id, sequence_id), label = datapoint
    image = Image.open(fp)
    if torch.cuda.is_available():
        return inference_transform(image).unsqueeze(0).cuda(), label
    return inference_transform(image).unsqueeze(0), label


# Cell
def show_heatmap_and_original(
    model, datapoint, inference_transform, show_for_label=True, show_for_prediction=False,
    label_type='tumor_class', show_activation_grid=False
):
    """Shows a heatmap corresponding the `model`'s prediction for `datapoint` after transforming the image
       using `inference_transform`. Assumes that the model was trained on labels of `label_type`. Optionally
       show the activation grid by specifying `show_activation_grid`."""
    assert label_type in ['tumor_class', 'tumor_type'], "Please specify one of tumor class or tumor type as label type."
    assert bool(show_for_label) != bool(show_for_prediction), "Only 1 of show_for_label and show_for_prediction can be specified as True."
    (fp, tumor, subtumor, magnification, slide_id, sequence_id), label = datapoint
    x, y = get_preprocessed_image(datapoint, inference_transform=inference_transform)

    grad_dict = {}
    activation_dict = {}
    def get_activation_hooks(submodule):
        def activation_grad_hook(module, input, output):
            output_hook = None
            def output_grad_hook(grad):
                assert grad.shape == output.shape
                grad_dict[submodule] = grad.detach()
                output_hook.remove()
            output_hook = output.requires_grad_().register_hook(output_grad_hook)

        def activation_output_hook(module, input, output):
            activation_dict[submodule] = output.detach()

        return (
            getattr(model, submodule).register_forward_hook(activation_grad_hook),
            getattr(model, submodule).register_forward_hook(activation_output_hook)
        )

    activation_grad_handle, activation_output_handle = get_activation_hooks('layer4')
    try:
        model.eval()
        model.zero_grad()
        output = model(x)
        probs = torch.softmax(output, -1).cpu()
        most_confident_class = BreaKHisDataset.index_mapping[label_type][torch.argmax(probs, -1).item()]
        most_confident_prob = torch.max(probs, -1)[0].item()
        label_prob = probs[:, y].item()
        print(
            "Model would have predicted %s (%.5f vs. %.5f)" %
            (most_confident_class, most_confident_prob, label_prob)
        )

        if show_for_label:
            print(
                "Showing activation heatmap for the given label: %s" %
                BreaKHisDataset.index_mapping[label_type][y]
            )
            output[:, y].backward()
        else:
            print(
                "Showing activation heatmap for the model's prediction: %s" %
                BreaKHisDataset.index_mapping[label_type][torch.argmax(probs, -1).item()]
            )
            output[:, torch.argmax(probs, -1).item()].backward()
        gradients = grad_dict['layer4']
        activations = activation_dict['layer4']
        pooled_gradients = torch.mean(gradients, dim=[0, 2, 3])
        activation_grid = (pooled_gradients.unsqueeze(0).unsqueeze(-1).unsqueeze(-1) * activations)
        activation_grid = torch.mean(activation_grid, dim=1).squeeze()
        activation_grid = np.maximum(activation_grid.detach().cpu(), 0)
        activation_grid /= torch.max(activation_grid)

        figsize = (25, 25)
        if show_activation_grid:
            fig, axes = plt.subplots(1, 3, figsize=figsize)
            activation_img = axes[0].matshow(activation_grid)
            fig.colorbar(activation_img, ax=axes[0], fraction=0.046, pad=0.04)
            ax_modifier = 1
        else:
            fig, axes = plt.subplots(1, 2, figsize=figsize)
            ax_modifier = 0

        img = np.array(Image.open(fp))
        resized_heatmap = activation_grid.numpy()
        resized_heatmap = cv2.resize(resized_heatmap, (img.shape[1], img.shape[0]))
        resized_heatmap = np.uint8(255 * resized_heatmap)
        resized_heatmap = cv2.applyColorMap(resized_heatmap, cv2.COLORMAP_JET)
        superimposed_img = resized_heatmap *0.4 + img
        assert cv2.imwrite('./map.jpg', superimposed_img)

        show_image(datapoint, ax=axes[ax_modifier])
        heatmap_img = axes[ax_modifier + 1].imshow(Image.open('./map.jpg'))
        fig.colorbar(heatmap_img, ax=axes[ax_modifier + 1], fraction=0.046, pad=0.04)
        plt.tight_layout()
        plt.show()
    finally:
        activation_grad_handle.remove()
        activation_output_handle.remove()