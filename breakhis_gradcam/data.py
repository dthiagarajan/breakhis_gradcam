# AUTOGENERATED! DO NOT EDIT! File to edit: 01_data.ipynb (unless otherwise specified).

__all__ = ['BreaKHisDataset', 'initialize_datasets']


# Cell
import numpy as np
import os
import torch

from PIL import Image
from torchvision import transforms

np.random.seed(31)
torch.manual_seed(31);


# Cell
class BreaKHisDataset(torch.utils.data.Dataset):
    """ PyTorch dataset definition of the BreaKHis dataset.

    Construction of the dataset object should be done using this
    class's method `initialize`. Simply providing the data directory
    where the data was downloaded is sufficient.
    """

    label_mapping = {
        'tumor_class': {'benign': 0, 'malignant': 1},
        'tumor_type': {
            subtumor: i for i, subtumor in enumerate([
                'adenosis', 'fibroadenoma', 'phyllodes_tumor', 'tubular_adenoma',
                'ductal_carcinoma', 'lobular_carcinoma', 'mucinous_carcinoma', 'papillary_carcinoma'
            ])
        }
    }
    index_mapping = {
        k: {iv: kv for (kv, iv) in v.items()} for (k, v) in label_mapping.items()
    }

    def __init__(self, dataset, transform=None):
        self.dataset = dataset
        self.transform = transform


    def __getitem__(self, index):
        (fp, tumor, subtumor, magnification, slide_id, sequence_id), label = self.dataset[index]
        image = Image.open(fp)
        data = self.transform(image) if image else image
        return data, torch.Tensor([label]).long().squeeze()

    def __len__(self):
        return len(self.dataset)


    @classmethod
    def _split(
        cls, dataset, split={'train': 0.8, 'val': 0.2}, criterion=['tumor_class'],
        split_transforms={'train': None, 'val': None}
    ):
        """ Splits `dataset` according to `split` percentages and `criterion`

        Arguments:
            `dataset`: the dataset to split (this is the output of `initialize`)
            `split` (Dict[str, float]): a mapping of strings to floats corresponding to the percentage
                in each split of the dataset; must add up to 1.
            `criterion` (List[str]): one of 'tumor_class' (benign/malignant) or
                                     'tumor_type' (e.g. adenosis) and/or 'magnification'
            `split_transforms` (Dict[str, torchvision.transforms]): a mapping of split IDs to the
                corresponding transforms.
        Returns:
            data_partitioned (Dict[str, List]): mapping of data corresponding to the split IDs
                given in `split`, and each split ID maps to a `BreaKHisDataset` encompassing the
                list of data points, with the proper percentage of the dataset allocated to each split ID.
        """
        assert sum([v for (_, v) in split.items()]) == 1, 'Please specify proper split percentages to sum to 1.'
        assert len(criterion) > 0, "Must specify at least 1 criterion to split on"
        split_by_tumor_class = 'tumor_class' in criterion
        split_by_tumor_type = 'tumor_type' in criterion
        assert bool(split_by_tumor_class) != bool(split_by_tumor_type), "Please only specify 1 of tumor type and class"
        split_by_magnification = 'magnification' in criterion

        data_split = {}
        for (tumor_class, tumor_type, slide_id, slide_data_mapping), label in dataset:
            if split_by_tumor_class or split_by_tumor_type:
                split_key = tumor_class if split_by_tumor_class else tumor_type
                if split_key not in data_split:
                    data_split[split_key] = (
                        {'40X': [], '100X': [], '200X': [], '400X': []}
                        if split_by_magnification else []
                    )
                for magnification, fp in slide_data_mapping.items():
                    queue = (
                        data_split[split_key][magnification] if split_by_magnification
                        else data_split[split_key]
                    )
                    queue.append((fp, label))
            else:
                for magnification, fp in slide_data_mapping.items():
                    if magnification not in data_split:
                        data_split[magnification] = []
                    data_split[magnification].append((fp, label))

        def partition(dataset):
            permutation = np.random.permutation(range(len(dataset)))
            init_percentage = 0.0
            split_dataset = []
            for split_id, split_percentage in split.items():
                start_index = int(init_percentage * len(permutation))
                end_index = int((init_percentage + split_percentage) * len(permutation))
                split_dataset.append(
                    (split_id, [dataset[index] for index in permutation[start_index:end_index]])
                )
                init_percentage += split_percentage
            return split_dataset

        for split_key, data_wrap in data_split.items():
            if type(data_wrap) == dict:
                for magnification, index_set in data_wrap.items():
                    data_wrap[magnification] = partition(index_set)
            else:
                data_split[split_key] = partition(data_wrap)

        data_partitioned = {k: [] for (k, _) in split.items()}
        for split_key, data_wrap in data_split.items():
            if type(data_wrap) == dict:
                for magnification, index_set in data_wrap.items():
                    for split_id, data in index_set:
                        data_partitioned[split_id].extend(data)
            else:
                for split_id, data in data_wrap:
                    data_partitioned[split_id].extend(data)

        return {k: cls(data_subset, split_transforms[k]) for k, data_subset in data_partitioned.items()}

    @classmethod
    def initalize(
        cls, data_dir, label='tumor_class', split={'train': 0.8, 'val': 0.2}, criterion=['tumor_class'],
        split_transforms={'train': None, 'val': None}
    ):
        """Initializes a PyTorch dataset object for the data contained in `data_dir`.

        Arguments:
            `data_dir` (str): the directory where the BreaKHis dataset was downloaded
            `label` (str): the label to use for the dataset (either 'tumor_class' or 'tumor_type')
            `split` (Dict[str, float]): a mapping of strings to floats corresponding to the percentage
                in each split of the dataset; must add up to 1.
            `criterion` (List[str]): one of 'tumor_class' (benign/malignant) or
                'tumor_type' (e.g. adenosis) and/or 'magnification'
            `split_transforms` (Dict[str, torchvision.transforms]): a mapping of split IDs to the
                corresponding transforms.
        Returns:
            data_partitioned (Dict[str, List]): mapping of data corresponding to the split IDs
                given in `split`, and each split ID maps to a `BreaKHisDataset` encompassing the
                list of data points, with the proper percentage of the dataset allocated to each split ID.
        """
        assert label in ['tumor_class', 'tumor_type'], "Please properly specify the label for this dataset."
        for split_id in split:
            assert split_id in split_transforms, """Split ID '%s' is not included in split_transforms""" % split_id
        _data_dir = os.path.join(data_dir, 'histology_slides/breast/')
        benign_dir = os.path.join(_data_dir, 'benign/SOB')
        benign_subtumors = ['adenosis', 'fibroadenoma', 'phyllodes_tumor', 'tubular_adenoma']
        benign_subdirs = [('benign', subtumor, os.path.join(benign_dir, subtumor)) for subtumor in benign_subtumors]
        malignant_dir = os.path.join(_data_dir, 'malignant/SOB')
        malignant_subtumors = ['ductal_carcinoma', 'lobular_carcinoma', 'mucinous_carcinoma', 'papillary_carcinoma']
        malignant_subdirs = [('malignant', subtumor, os.path.join(malignant_dir, subtumor)) for subtumor in malignant_subtumors]
        flatten = lambda l: [item for sublist in l for item in sublist]
        benign_subsubdirs = flatten([
            [(tumor, subtumor, subsubdir, os.path.join(subdir, subsubdir)) for subsubdir in os.listdir(subdir)]
            for tumor, subtumor, subdir in benign_subdirs
        ])
        malignant_subsubdirs = flatten([
            [(tumor, subtumor, subsubdir, os.path.join(subdir, subsubdir)) for subsubdir in os.listdir(subdir)]
            for tumor, subtumor, subdir in malignant_subdirs
        ])
        for (_, _, _, benign_subsubdir), (_, _, _, malignant_subsubdir) in zip(benign_subsubdirs, malignant_subsubdirs):
            assert os.path.isdir(benign_subsubdir), "%s is not a valid directory" % benign_subsubdir
            assert os.path.isdir(malignant_subsubdir), "%s is not a valid directory" % malignant_subsubdir
        magnifications = ['40X', '100X', '200X', '400X']
        benign_data = []
        malignant_data = []
        for (tumor, subtumor, slide_number, benign_subsubdir) in benign_subsubdirs:
            data_mapping = {}
            slide_id = slide_number.split('_')[-1].split('-')[-1]
            for magnification in magnifications:
                magnification_subsubdir = os.path.join(benign_subsubdir, magnification)
                for slide in os.listdir(magnification_subsubdir):
                    sequence_id = int(slide.split('.')[0].split('-')[-1])
                    if sequence_id not in data_mapping:
                        data_mapping[sequence_id] = {}
                    data_mapping[sequence_id][magnification] = (
                        os.path.join(magnification_subsubdir, slide),
                        tumor, subtumor, magnification, slide_id, sequence_id
                    )
            benign_data.append((tumor, subtumor, slide_id, data_mapping))
        for (tumor, subtumor, slide_number, malignant_subsubdir) in malignant_subsubdirs:
            data_mapping = {}
            slide_id = slide_number.split('_')[-1].split('-')[-1]
            for magnification in magnifications:
                magnification_subsubdir = os.path.join(malignant_subsubdir, magnification)
                for slide in os.listdir(magnification_subsubdir):
                    sequence_id = int(slide.split('.')[0].split('-')[-1])
                    if sequence_id not in data_mapping:
                        data_mapping[sequence_id] = {}
                    data_mapping[sequence_id][magnification] = (
                        os.path.join(magnification_subsubdir, slide),
                        tumor, subtumor, magnification, slide_id, sequence_id
                    )
            malignant_data.append((tumor, subtumor, slide_id, data_mapping))

        all_data = []
        total = 0
        for tumor, subtumor, slide_id, data_mapping in benign_data:
            for cell_id, file_mapping in data_mapping.items():
                total += len(file_mapping)
                all_data.append((
                    (tumor, subtumor, slide_id, file_mapping),
                    cls.label_mapping[label][subtumor if label == 'tumor_type' else tumor]
                ))
        for tumor, subtumor, slide_id, data_mapping in malignant_data:
            for cell_id, file_mapping in data_mapping.items():
                total += len(file_mapping)
                all_data.append((
                    (tumor, subtumor, slide_id, file_mapping),
                    cls.label_mapping[label][subtumor if label == 'tumor_type' else tumor]
                ))
        assert total == 7909, "Some images might be missing."

        return cls._split(
            all_data, split=split, criterion=criterion, split_transforms=split_transforms
        )



# Cell
def initialize_datasets(
    data_dir, label='tumor_class', split={'train': 0.8, 'val': 0.2}, criterion=['tumor_class'],
    split_transforms={'train': None, 'val': None}
):
    """Returns a `BreaKHisDataset` object for the data contained in `data_dir`."""
    return BreaKHisDataset.initalize(
        data_dir, label=label, criterion=criterion, split=split, split_transforms=split_transforms
    )